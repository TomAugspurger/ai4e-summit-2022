{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932144cf-176d-4733-92fe-55bc7eedaf1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Planetary Computer Hub Overview\n",
    "\n",
    "The Planetary Computer Hub is a *convenient* place to do geospatial data analysis on Azure. There are many ways to compute on Azure (VMs, Azure Functions, Kubernetes, Azure ML, ...). You can use the Planetary Computer data and APIs from any of them (see https://planetarycomputer.microsoft.com/docs/concepts/computing/), but make sure the compute is in the **West Europe** Azure region.\n",
    "\n",
    "You can sign in at https://planetarycomputer.microsoft.com/compute. Request an account at https://planetarycomputer.microsoft.com/account/request if you haven't already.\n",
    "\n",
    "<img src=\"https://planetarycomputer.microsoft.com/_images/hub-login.png\" width=\"25%\"/>\n",
    "\n",
    "Once signed in, you choose an *environment*\n",
    "\n",
    "<img src=\"https://planetarycomputer.microsoft.com/_images/hub-profiles.png\" width=\"25%\"/>\n",
    "\n",
    "Check out the [JupyterLab](https://jupyterlab.readthedocs.io/) docs if you're new to JupyterLab and want to learn more. The main thing for today is `shift+Enter`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789d4ed-b801-40b1-b405-da605d77cf4e",
   "metadata": {},
   "source": [
    "## Cloud-native Geospatial\n",
    "\n",
    "Why do we care about doing our data analysis in the cloud?\n",
    "\n",
    "1. There's too much data. It simply doesn't fit on a single hard drive.\n",
    "2. You potentially want access to all of it. Thousands of others potentially want to access all of it.\n",
    "3. We want to do more complicated and compute-intensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c37998-a5d3-4422-8a3e-7b98d05d7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!time gdalinfo /vsicurl/https://naipeuwest.blob.core.windows.net/naip/v002/ia/2019/ia_60cm_2019/42091/m_4209150_sw_15_060_20190828.tif > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ad12c-d77c-4e0a-aa05-7502b898ecb7",
   "metadata": {},
   "source": [
    "I ran that same command on my laptop, from my home. It took *much* longer.\n",
    "\n",
    "```console\n",
    "> time ./gdalinfo /vsicurl/https://naipeuwest.blob.core.windows.net/naip/v002/ia/2019/ia_60cm_2019/42091/m_4209150_sw_15_060_20190828.tif > /dev/null\n",
    "\n",
    "real    0m6.706s\n",
    "user    0m0.351s\n",
    "sys     0m0.097s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5bd9d2-54bd-46bc-b637-45484efb29ae",
   "metadata": {},
   "source": [
    "So the most important point: **put your compute next to the data**. It's faster and cheaper. All the Planetary Computer data is in the **West Europe** region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a481f58-acbe-48fb-9ddf-c5b440c18536",
   "metadata": {},
   "source": [
    "## The Filesystem\n",
    "\n",
    "There are two parts to your filesystem:\n",
    "\n",
    "1. Your *home* directory, at `/home/jovyan/`, which persists across sessions. Put your code, notebooks, outputs, etc. here.\n",
    "2. Everything else, which does *not* persist across sessions.\n",
    "\n",
    "The size of your home directory is fairly limited. It's really intended for small things like code. It's *not* intended for large amounts of data.\n",
    "\n",
    "If you do need to (temporarily) store lots of data, put it in `/tmp`. This might be helpful for file formats like GRIB2 that can't be streamed over the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885612b-c534-4058-8240-9710f98e7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as td:\n",
    "    # save temporary data files here\n",
    "    print(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b9063d-9613-4e08-a7d6-2dcac6795991",
   "metadata": {},
   "source": [
    "But note that anything saved outside of `/tmp` will not be available the next time you start your notebook server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df842eba-1f25-4f2b-9b44-b7b31062cb07",
   "metadata": {},
   "source": [
    "## The software environment\n",
    "\n",
    "When you logged in, you picked the software environment (Python, R, Tensorflow, PyTorch, ...). This consists of a conda environment at `/srv/conda/envs/notebook`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1d6f1-86f8-4f84-b81a-2e25fb81ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $CONDA_PREFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cddd77-c885-42af-8479-dd592198a7c7",
   "metadata": {},
   "source": [
    "Notice that's outside of the home directory, so any changes you make to the software environment will be lost when your session restarts. Those environments are created using a set of Dockerfiles at https://github.com/Microsoft/planetary-computer-containers. Reach out there if you have a package that would be appropriate to add to the base environment.\n",
    "\n",
    "You can install additional packages \"at runtime\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d64643-2a7b-4cdf-8f47-6e7607d8fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cyberpandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193d137-81fe-420a-bbef-21a567d4db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cyberpandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da39bc-86c6-491c-a2bc-3de8f9cf462e",
   "metadata": {},
   "source": [
    "You can also install packages using conda / mamba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3bff9-3cad-444e-b868-17b26d10c62b",
   "metadata": {},
   "source": [
    "## Scaling with Dask\n",
    "\n",
    "<img src=https://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg width=\"10%\">\n",
    "\n",
    "Dask is a way to scale your Python code. It can be helpful when you're working with datasets that are larger than memory, or you're running some computationally expensive job that can be parallized.\n",
    "The Planetary Computer Hub includes a service to easily create Dask clusters. In short: you get to distribute your computation on many machines without having to worry about the hassles of actually setting up machines, managing environments, networking, etc.\n",
    "\n",
    "We'll spend a few minutes learning about Dask, but many of the lessons are applicable to other parallel computing environments.\n",
    "\n",
    "The core idea behind Dask, and any other parallel computing framework, is to get some work done faster by splitting some large job into smaller pieces and running those smaller pieces in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a040b-1feb-4b94-a297-ccc2bf0f336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.distributed\n",
    "\n",
    "client = dask.distributed.Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013be618-c616-41b2-b581-02c244356b7e",
   "metadata": {},
   "source": [
    "Let's define a couple of functions to simulate real work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04898141-0023-4cc7-8880-3ae217f72d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def inc(x):\n",
    "    time.sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9666089-078e-4018-840e-8e0def35c69c",
   "metadata": {},
   "source": [
    "We'll run a workload that should take about 3 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f467a32-3e07-4964-8da0-ec96196e7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = inc(1)\n",
    "y = inc(2)\n",
    "z = add(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be465e-a7c0-42c1-a68e-907ee93435f6",
   "metadata": {},
   "source": [
    "Now, let's parallelize that with Dask, specifically [`dask.delayed`](https://docs.dask.org/en/stable/delayed.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392854ae-6cd8-4696-b767-58b866f24157",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = dask.delayed(inc)(1)\n",
    "y = dask.delayed(inc)(2)\n",
    "z = dask.delayed(add)(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d400cb-ef42-4943-a1c1-c0d4ab8230a4",
   "metadata": {},
   "source": [
    "What just happened? We haven't actually run our computation yet. `dask.delayed`, and several other components of Dask, are *lazy*. They don't run your computation until you actually ask it to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fa946-55bc-470c-a627-9932861487ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73f2da-53a2-46c1-90f3-f0c6675a1728",
   "metadata": {},
   "source": [
    "Instead, we've built up a kind of recipe for our computation: a task graph that, when executed, will give us our result. We can visualize the task graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f4e534-ce92-4440-a7de-a554b7299506",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a1966d-20fc-4cfe-941d-2e2f4eee4a9d",
   "metadata": {},
   "source": [
    "And get the actual result with `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee24e86-adcc-40e9-aaa1-29db037bc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d5a2e-1e45-4a5a-8b8f-0c409d227df5",
   "metadata": {},
   "source": [
    "We can see a few things. First, if you had your Task Stream plot open, you'll see that Dask did indeed run the two `inc` tasks in parallel. Second, you'll see that the overall time was just over 2s, higher than our theoretical best time of 2s. Dask does incur some overhead related to task scheduling and data movement. See https://docs.dask.org/en/stable/best-practices.html for more.\n",
    "\n",
    "So that's Dask in a nutshell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca37d886-65bd-47e8-8928-c6c9a3621de3",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.dask.org/en/stable/_images/dask-overview.svg\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b3c4c-a9ee-47d4-b28c-ecc422ccbb0c",
   "metadata": {},
   "source": [
    "With Dask, you can parallelize your workload on a single machine, or a distributed cluster of machines. Typically, distributed computing comes with a bunch of headaches around infrastructure: setting up the machines, getting them talking to eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed487531-857f-45ca-b745-fa42102549e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_gateway\n",
    "\n",
    "cluster = gateway = dask_gateway.GatewayCluster()\n",
    "cluster.scale(2)\n",
    "client = cluster.get_client()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8dbf3-ad9c-48e8-863b-bf9176abc585",
   "metadata": {},
   "source": [
    "That created a cluster with all the default options. You can customize a few things when created your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f878e-c6a0-4152-9ebc-97437cb84230",
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = dask_gateway.Gateway()\n",
    "\n",
    "options = gateway.cluster_options()\n",
    "options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb82b2-a7a1-4ed8-acc3-524f642b5a87",
   "metadata": {},
   "source": [
    "Pass those to `gateway.new_cluster()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb084d-5ed1-4fa3-a838-85eb1ed9eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
